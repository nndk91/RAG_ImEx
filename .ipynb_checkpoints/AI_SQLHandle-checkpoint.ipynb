{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "9bde428d-142d-44d3-96f8-b5824fa066b0",
   "metadata": {},
   "outputs": [],

   "source": [
    "!pip install -q python-dotenv\n",
    "!pip install -q gradio\n",
    "!pip install -q unstructured\n",
    "!pip install -q openpyxl\n",
    "!pip install -q tiktoken\n",
    "!pip install -q chromadb\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q --upgrade langchain\n",
    "!pip install -q -U langchain-chroma\n",
    "!pip install -q -U langchain-google-vertexai\n",
    "!pip install -q -U langchain-community\n",
    "!pip install -q -U langchain langchain-huggingface\n",
    "!pip install -q sqlalchemy\n",
    "!pip install -q pymysql\n",
    "!pip install -q openai mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45246de-14da-4a92-9528-62fd938be717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",

   "execution_count": 133,

   "id": "bd8b97c2-cd82-4206-b1d1-8fb70009fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import chromadb\n",
    "import mysql.connector\n",
    "import openai\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from chromadb import chromadb\n",
    "from sklearn.manifold import TSNE\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, insert, Float, DateTime, inspect\n",
    "#from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 2,

   "id": "9f27be11-fc8d-4dbb-a38d-3e44b7cd5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader, UnstructuredExcelLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings, SentenceTransformerEmbeddings, HuggingFaceEmbeddings \n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_google_vertexai import ChatVertexAI #Import ChatVertexAI from langchain_google_vertexai\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from chromadb import Client, Settings "
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "b3556cb5-6799-41ec-8743-c23c98d942c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "load_dotenv()\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY_2', 'your-key-if-not-using-env')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['MYSQL_KEYPW'] = os.getenv('MYSQL_KEYPW', 'your-key-if-not-using-env')\n",
    "print(os.environ['OPENAI_API_KEY'])"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 203,

   "id": "24825994-557c-447d-90a9-afeff74765b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "Gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "MODEL = \"gemini-1.5-flash\" \n",
    "#Testing Gemini AI\n",
    "#response = model.generate_content(\"Explain how AI works\")\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 168,

   "id": "afad22ce-31e0-41a2-9cf2-cc7ad55c014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 169,

   "id": "edbb382d-7c7b-4b53-921f-443a07e5ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge base is in /RAG_ImEx/Data\n",
    "#knowledge_base_path = \"Data/*\"  \n",
    "# Knowledge base is in /RAG_ImEx/Data_test\n",
    "knowledge_base_path = \"Data_test/*\"  "
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 170,

   "id": "5bfad66d-baf4-4386-b2ce-0f4572a73003",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    'MA HQ', 'MA HAI QUAN', 'MA CHI CUC',\n",
    "    'TEN HAI QUAN', 'SO DT', 'DIA DIEM CHO THONG QUAN',\n",
    "    'DIA DIEM CHO THONG QUAN', 'DIA DIEM NHAN HANG',\n",
    "    'DIA DIEM DO HANG', 'DIA DIEM XEP HANG', 'P.TIEN V.CHUYEN', 'TRI GIA',\n",
    "    'NUOC NK','LOAI HINH'\n",
    "]\n",
    "address_cols = ['dia chi 1', 'dia chi 2', 'dia chi 3', 'dia chi 4']\n",
    "\n",
    "header_translations = {\n",
    "    \"MA LH\": \"Import_Code\", \n",
    "    \"NHA NHAP KHAU\" : \"Importer_Name\",\n",
    "    \"DIA CHI\" : \"Importer_Address\",\n",
    "    \"nha xuat khau\" : \"Exporter_Name\",\n",
    "    \"DIA CHI XK\" : \" Exporter_Address\",\n",
    "    \"DON VI DOI TAC\":\"Partner_Company\", \n",
    "    \"DIA CHI DON VI DOI TAC\" : \"Partner_Address\",\n",
    "    \"DK TT\": \"Payment_term\",\n",
    "    \"DK GH\": \"Incoterms\",\n",
    "    \"TI GIA\": \"Exchange_Rate\",\n",
    "    \"NGAY\" : \"Date\",\n",
    "    \"MA HANG\" : \"HSCODE\",\n",
    "    \"TEN HANG\": \"Product_Info\", \n",
    "    \"LUONG\": \"Quantity\",\n",
    "    \"DVT\" : \"Unit\",\n",
    "    \"DON GIA\" : \"Unit_Price\",\n",
    "    \"MA NT\": \"Payment_Currency\",\n",
    "    \"THUE XNK\" : \"Import_Tax\",\n",
    "    \"MA DOANH NGHIEP\" : \"Tax_ID\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 171,

   "id": "e043ac7a-94f4-4fa3-9b55-7864628f657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_excel_files(folder_path, excel_type, columns_to_remove, address_cols, header_translations):\n",
    "    # Create an empty DataFrame to hold combined data\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    # Use glob to find all Excel files in the specified folder that match the pattern\n",
    "    excel_files = glob.glob(os.path.join(folder_path, excel_type))\n",
    "    \n",
    "    # Print found files for debugging\n",
    "    print(f\"Found files: {excel_files}\")\n",
    "    \n",
    "    for file in excel_files:\n",
    "        # Load each Excel file into a DataFrame\n",
    "        df = pd.read_excel(file)\n",
    "        \n",
    "        # Convert all column names to lowercase\n",
    "        df.columns = df.columns.str.lower()\n",
    "        \n",
    "        # Print column names for debugging\n",
    "        #print(f\"Columns in {file}: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Remove specified columns (in lowercase)\n",
    "        columns_to_remove_lower = [col.lower() for col in columns_to_remove]\n",
    "        df.drop(columns=columns_to_remove_lower, inplace=True, errors='ignore')\n",
    "        \n",
    "        # Check if address columns exist before combining them (in lowercase)\n",
    "        existing_address_cols = [col for col in address_cols if col.lower() in df.columns]\n",
    "        \n",
    "        if existing_address_cols:\n",
    "            # Combine address columns into a single column\n",
    "            df['dia chi don vi doi tac'] = df[existing_address_cols].fillna('').agg(' '.join, axis=1)\n",
    "            # Remove the original address columns after combining\n",
    "            df.drop(columns=existing_address_cols, inplace=True, errors='ignore')\n",
    "        else:\n",
    "            print(f\"No address columns found in {file}. Skipping combination.\")\n",
    "        \n",
    "        # Rename headers according to the provided translations (keys should also be in lowercase)\n",
    "        header_translations_lower = {k.lower(): v for k, v in header_translations.items()}\n",
    "        df.rename(columns=header_translations_lower, inplace=True)\n",
    "\n",
    "        # Clean up column names (remove trailing spaces, etc.)\n",
    "        df.columns = df.columns.str.strip()  # Remove leading/trailing spaces\n",
    "        df.columns = df.columns.str.replace(' ', '_')  # Replace spaces with underscores (optional)\n",
    "        df.columns = df.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True) # Remove special characters (optional)\n",
    "        df.columns = df.columns.str.lower() # Convert to lowercase (optional, but recommended)\n",
    "\n",
    "        \n",
    "        # Append the processed DataFrame to the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    # Print final combined DataFrame shape and contents for debugging\n",
    "    #print(f\"Final combined DataFrame shape: {combined_df.shape}\")\n",
    "    #print(combined_df.head())  # Display first few rows\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 172,

   "id": "aa3867f4-49b3-44fa-a854-2dc55c9fd757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: ['Data_test\\\\Raw Data\\\\72NK.T1.2024test.xlsx', 'Data_test\\\\Raw Data\\\\72NK.T3.2024test.xlsx']\n",
      "Found files: ['Data_test\\\\Raw Data\\\\72XK.T6.2024test.xlsx', 'Data_test\\\\Raw Data\\\\72XK.T8.2021test.xlsx']\n"
     ]
    }
   ],
   "source": [
    "combined_df_NK = combine_excel_files(knowledge_base_path,'72NK*.xlsx', columns_to_remove, address_cols, header_translations)\n",
    "combined_df_XK = combine_excel_files(knowledge_base_path,'72XK*.xlsx', columns_to_remove, address_cols, header_translations)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 199,

   "id": "3c34eb60-5531-46d9-85f8-e9df505e23eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Index(['import_code', 'tax_id', 'importer_name', 'importer_address',\n",
      "       'partner_company', 'incoterms', 'payment_currency', 'exchange_rate',\n",
      "       'date', 'hscode', 'product_info', 'quantity', 'unit', 'unit_price',\n",
      "       'partner_address'],\n",
      "      dtype='object')\n"

     ]
    }
   ],
   "source": [
    "#print(combined_df_XK.columns)\n",

    "print(combined_df_NK.columns)"
 
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 173,
 
   "id": "1a3db2aa-0820-4fc0-953b-de6ecc4b5592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dataframe_to_sql(df, table_name, db_url, if_exists='fail'):\n",
    "    \"\"\"\n",
    "    Inserts a DataFrame into a SQL database table.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame to insert.\n",
    "    - table_name: The name of the table in the database.\n",
    "    - db_url: The database connection URL.\n",
    "    - if_exists: What to do if the table already exists. Options are 'fail', 'replace', 'append'.\n",
    "    \"\"\"\n",
    "    # Create a database engine\n",
    "    engine = create_engine(db_url)\n",
    "    \n",
    "    # Insert the DataFrame into the SQL table\n",
    "    df.to_sql(name=table_name, con=engine, if_exists=if_exists, index=False)\n",
    "\n",
    "# Example usage\n",
    "# Define your database URL (replace with your actual credentials)\n",

    "db_url = \"mysql+pymysql://root:\"+Mysqlkey+\"@localhost:3306/my_database\"\n",

    "\n",
    "# Assuming combine_df is your DataFrame that you want to insert\n",
    "insert_dataframe_to_sql(combined_df_NK, 'combined_table_nk', db_url, if_exists='replace')\n",
    "insert_dataframe_to_sql(combined_df_XK, 'combined_table_xk', db_url, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 200,

   "id": "2c155885-9d2b-41ff-b46e-4aeb924d6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your OpenAI API key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Replace with your MySQL credentials\n",
    "db_host = \"localhost\"\n",
    "db_user = \"root\"\n",
    "db_password = os.environ['MYSQL_KEYPW']\n",
    "db_name = \"my_database\"\n",
    "\n",
    "def execute_sql_from_user_query(user_query):\n",
    "    try:\n",
    "        # 1. Translate user query to SQL using OpenAI Chat Completion\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"\n",
    "            Translate following user query into valid SQL command for MySQL, \n",

    "            Data for importing from tables named 'combined_table_nk'\n",
    "            Headers for import data including\n",
    "            'import_code', 'tax_id', 'importer_name', 'importer_address',\n",
    "            'partner_company', 'incoterms', 'payment_currency', 'exchange_rate',\n",
    "            'date', 'hscode', 'product_info', 'quantity', 'unit', 'unit_price',\n",
    "            'partner_address'],\n",
    "           \n",
    "            Data for exporting from tables named 'combined_table_xk'\n",
    "            Headers for export data including\n",
    "            'import_code', 'tax_id', 'exporter_name', 'exporter_address',\n",
    "            'partner_company', 'incoterms', 'payment_currency', 'exchange_rate',\n",
    "            'date', 'hscode', 'product_info', 'quantity', 'unit', 'unit_price',\n",
    "            'partner_address'\n",

    "\n",
    "            When user asking for a data,find the relavant data in the contents \n",
    "            using SQL LIKE '%contents%' and show all the columns.\n",
    "\n",
    "            Do not allow user to delete, change, remove, appending any data, columns, table.\n",
    "            \n",

    "            Just send out SQL code, no further comment or explain\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": user_query},\n",
    "        ]\n",
    "\n",
    "        response = openai.chat.completions.create(  # Correct way to call Chat Completion\n",
    "            model=\"gpt-3.5-turbo\",  # Or gpt-4 if you have access\n",
    "            messages=messages,\n",
    "            max_tokens=200,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "\n",
    "        sql_command = response.choices[0].message.content.strip()\n",
    "\n",
    "        print(f\"Generated SQL: {sql_command}\")\n",
    "\n",
    "        # 2. Connect to MySQL (same as before)\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=db_host,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            database=db_name\n",
    "        )\n",
    "\n",
    "        mycursor = mydb.cursor()\n",
    "\n",
    "        # 3. Execute the SQL command (same as before)\n",
    "        mycursor.execute(sql_command)\n",
    "\n",
    "        # 4. Fetch the results (same as before)\n",
    "        results = mycursor.fetchall()\n",
    "\n",
    "        # 5. Convert results to Pandas DataFrame (same as before)\n",
    "        column_names = [description[0] for description in mycursor.description]\n",
    "        df = pd.DataFrame(results, columns=column_names)\n",
    "\n",
    "        # 6. Close the connection (same as before)\n",
    "        mydb.close()\n",
    "\n",
    "        return df\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        return f\"MySQL Error: {err}\"\n",
    "    except openai.APIError as err:  # Corrected OpenAI error handling!\n",
    "        return f\"OpenAI API Error: {err}\"\n",
    "    except Exception as err:\n",
    "        return f\"An error occurred: {err}\"\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 12,

   "id": "3665af98-9479-4908-9eac-3715a85a8398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {

     "data": {
      "text/plain": [
       "'\\nuser_query = input(\"Enter your query: \")\\nresult = execute_sql_from_user_query(user_query)\\n\\nif isinstance(result, pd.DataFrame):\\n    print(result)\\nelif isinstance(result, str):  # Error message\\n    print(result)\\n    '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"

    }
   ],
   "source": [
    "# Usage\n",

    "\n",
    "'''\n",

    "user_query = input(\"Enter your query: \")\n",
    "result = execute_sql_from_user_query(user_query)\n",
    "\n",
    "if isinstance(result, pd.DataFrame):\n",
    "    print(result)\n",
    "elif isinstance(result, str):  # Error message\n",

    "    print(result)\n",
    "    '''"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 1,

   "id": "5c9666d4-d690-4c63-970f-3cdc2a1c94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping in a function - note that history isn't used, as the memory is in the conversation_chain\n",
    "def chat(message, history=[]):  # Accept both message and history\n",
    "    try:\n",
    "        result = execute_sql_from_user_query(message)\n",
    "\n",
    "        if isinstance(result, pd.DataFrame):\n",
    "            # Best practice: Return a string representation of the DataFrame for Gradio\n",
    "            return str(result)  # Or result.to_string() for more control\n",
    "        elif isinstance(result, str):  # Error message\n",
    "            return result\n",
    "        else:  # Handle other potential return types\n",
    "            return \"Unexpected result type from SQL execution.\"\n",
    "\n",
    "    except Exception as e:  # Catch and display exceptions\n",
    "        return f\"Error during SQL execution: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 2,

   "id": "dc700dfd-f935-4281-8155-1bfbb59ccb67",
   "metadata": {},
   "outputs": [
    {

     "ename": "NameError",
     "evalue": "name 'gr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# And in Gradio:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m view \u001b[38;5;241m=\u001b[39m \u001b[43mgr\u001b[49m\u001b[38;5;241m.\u001b[39mChatInterface(chat, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlaunch(inbrowser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gr' is not defined"

     ]
    }
   ],
   "source": [
    "# And in Gradio:\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f44a887-65b4-476f-ab40-bbef2700aae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
